{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "when the user trying to submit tickets, show similar tickets\n",
    "\n",
    "# Category\n",
    "Recommendation of the text(review or description)\n",
    "\n",
    "# Approach\n",
    "Unsupervised Learning: Clustering Algorithm - KMeans, Different algorithms.\n",
    "\n",
    "# Import required libraries:\n",
    "    - EDA based libraries (Numpy, pandas, matplotlib, seaborn)\n",
    "    - ML unsupervised learning libraries (Scikit-Learn)\n",
    "\n",
    "# EDA\n",
    "\n",
    "# Model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Desktop/WorkSpace/Recommendation/data.csv\")\n",
    "df = df.iloc[:,:3]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"corrected_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Combined_Text\"] = df[\"Summary\"]+\" \"+df[\"Description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -qq install matplotlib\n",
    "!pip -qq install pandas\n",
    "!pip -qq install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "comment_words = ''\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "def generate_wordCloud(comment_words,title):\n",
    "\twordcloud = WordCloud(width = 800, height = 800,background_color ='white',stopwords = stopwords,\n",
    "\t\t\t\t\t   min_font_size = 10).generate(comment_words)\n",
    "\tplt.figure(figsize = (8, 8), facecolor = None)\n",
    "\tplt.imshow(wordcloud)\n",
    "\tplt.axis(\"off\")\n",
    "\tplt.tight_layout(pad = 0)\n",
    "\tplt.title(title,fontsize = 50)\n",
    "\tplt.show()\n",
    "\treturn wordcloud\n",
    "\n",
    "summary_col = df[\"Summary\"].dropna().values\n",
    "Summary_corpus = \" \".join([str(i) for i in summary_col]).lower()\n",
    "generate_wordCloud(Summary_corpus,\"Summary Word Cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_col = df[\"Description\"].dropna().values\n",
    "desc_corpus = \" \".join([str(i) for i in desc_col]).lower()\n",
    "generate_wordCloud(desc_corpus,\"Description Word Cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_col = df[\"Combined_Text\"].dropna().values\n",
    "comb_corpus = \" \".join([str(i) for i in comb_col]).lower()\n",
    "generate_wordCloud(comb_corpus,\"Combined text Word Cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "tokens = nltk.word_tokenize(Summary_corpus)\n",
    "bgs = nltk.ngrams(tokens,3)\n",
    "fdist = nltk.FreqDist(bgs)\n",
    "fdist.plot(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Desc_sentence_len\"] = df[\"Description\"].str.len()\n",
    "df[\"Summary_sentence_len\"] = df[\"Summary\"].str.len()\n",
    "df[\"Summary_sentence_len\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "data = df[\"Summary_sentence_len\"].values\n",
    "res = sns.distplot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Desc_words_count\"] = [len(str(d).split(\" \")) for d in df[\"Description\"]]\n",
    "df[\"Summary_words_count\"] = [len(str(d).split(\" \")) for d in df[\"Summary\"]]\n",
    "df[\"Summary_words_count\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pylcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylcs\n",
    "\n",
    "excel_name =\"Desktop/WorkSpace/Recommendation/corrected_data.csv\"\n",
    "threshold = 0.4\n",
    "nrows=6000\n",
    "\n",
    "df = pd.read_csv(excel_name, nrows=nrows)\n",
    "to_cmp = df['Summary'].to_list()\n",
    "to_desc = df['Description'].to_list()\n",
    "# Defect_id = df['Key'].to_list()\n",
    "# service_id = df['Service Area'].to_list()\n",
    "# status_id = df['Status'].to_list()\n",
    "\n",
    "ref = \"\"\n",
    "my_index = []\n",
    "mylist = []\n",
    "my_len = len(to_cmp)\n",
    "mark = [0]*(len(df))\n",
    "\n",
    "def Calculate_RougeL(hypothesis , reference ):\n",
    "    res = pylcs.lcs_sequence_length(hypothesis , reference)\n",
    "    precision = res / len(str(hypothesis))\n",
    "    recall =  res / len(str(reference))\n",
    "    f1 = (2 * precision * recall) / (precision + recall + 1)\n",
    "    return f1\n",
    "\n",
    "def similar_defects_within_componet():\n",
    "\n",
    "    # MARK SIMILAR DEFECTS\n",
    "    for i in range(my_len):\n",
    "        # print(i)\n",
    "        myindex = []\n",
    "        mylist.append([])\n",
    "        mylist[i].append(i)\n",
    "\n",
    "        for j in range(i+1,my_len):\n",
    "            if mark[j] == 0:\n",
    "                # SEARCH BY TITLE\n",
    "                f1  = Calculate_RougeL(str(to_cmp[i]), str(to_cmp[j]))\n",
    "                if f1 >= threshold:\n",
    "                    # SEARCH BY DESCRIPTION\n",
    "                    f2 = Calculate_RougeL(str(to_desc[i]), str(to_desc[j]))\n",
    "                    if f2 >= threshold:\n",
    "                        mylist[i].append(j)\n",
    "                        mark[j] = 1\n",
    "\n",
    "    print(\"Listing similar defects \")\n",
    "    mylist.sort(key=len)\n",
    "\n",
    "    for i in range(len(mylist)):\n",
    "        if len(mylist[i]) !=0 :\n",
    "            myitems = mylist[i]\n",
    "            print(str(len(myitems)))\n",
    "            for items in myitems:\n",
    "                print(str(items) + \"  \"  + str(to_cmp[items]) + \"  \"  + str(items) + \"  \" )\n",
    "\n",
    "\n",
    "    print(\"Sort by Top 10 duplicates\")\n",
    "    res = mylist[-10:]\n",
    "    for i in range(0,max(10,len(res))):\n",
    "        myitems = res[i]\n",
    "        print(str(to_cmp[myitems[0]]) + \"  \" +  \"[\" + str(len(myitems)) + \"]\" )\n",
    "        for items in myitems:\n",
    "            print(to_cmp[items])\n",
    "        print(\"  \")\n",
    "\n",
    "similar_defects_within_componet()\n",
    "# Calculate_RougeL(\"Movie is good\",\"Movie is good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pylcs.lcs_sequence_length(\"Movie is very good\",\"Movie is good\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dict(zip([1,5,3],[\"a\",\"b\",\"c\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Recommendation_Streamlit_Web_App/Data/all.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
